{
  "id": "case-15",
  "number": 15,
  "title": "A Avalanche de Cache",
  "subtitle": "Todas as entradas de cache expiram simultaneamente, esmagando o banco de dados",
  "brief": {
    "narrative": "√â meia-noite em Distributia e o banco de dados acabou de colapsar. Todo s√°bado √† meia-noite, o job de aquecimento de cache roda e carrega todos os dados criminais da semana no Redis com um TTL uniforme de 7 dias. Isso significa que todo s√°bado √† meia-noite, todas essas entradas expiram exatamente ao mesmo tempo. O banco de dados acabou de receber 2,8 milh√µes de consultas em menos de 60 segundos, j√° que cada cache miss disparou uma leitura no banco. O pool de conex√µes do servidor de banco de dados est√° esgotado, consultas est√£o expirando por timeout, e todo o departamento est√° efetivamente √†s cegas. Isso j√° aconteceu 3 s√°bados seguidos. O Chefe Partition quer que seja resolvido de vez, Detetive.",
    "symptoms": [
      "Pool de conex√µes do banco de dados esgotado todo s√°bado √† meia-noite",
      "2,8 milh√µes de cache misses ocorrem dentro de uma janela de 60 segundos",
      "Cache Redis vai de 99% de taxa de acerto para 0% instantaneamente √† meia-noite",
      "Todos os servi√ßos experimentam timeouts durante a janela de reconstru√ß√£o do cache"
    ],
    "objective": "Identificar por que a expira√ß√£o em massa do cache est√° causando sobrecarga no banco de dados e recomendar uma estrat√©gia para evitar expira√ß√£o sincronizada."
  },
  "diagram": {
    "nodes": [
      {
        "id": "redis-cache",
        "type": "server",
        "label": "Redis Cache",
        "status": "degraded",
        "position": { "x": 350, "y": 50 },
        "inspectable": true,
        "inspectData": {
          "title": "Cluster de Cache Redis",
          "logs": [
            "[00:00:00] INFO: TTL expiry triggered for batch-loaded keys",
            "[00:00:01] WARN: 2,847,000 keys expired simultaneously",
            "[00:00:02] INFO: Cache hit rate dropped from 99.2% to 0.1%",
            "[00:00:03] WARN: All incoming requests are cache MISSes"
          ],
          "data": {
            "Status": "EMPTY (mass expiry)",
            "Keys Before Midnight": "2,847,000",
            "Keys After Midnight": "312",
            "Hit Rate": "0.1% (was 99.2%)",
            "TTL Policy": "Uniform 7 days for all keys",
            "Cache Warm Job": "Saturdays 00:00 ‚Äî loads all keys with same TTL"
          },
          "status": "Todas as chaves expiraram de uma vez devido a TTL id√™ntico. Cache est√° efetivamente vazio."
        }
      },
      {
        "id": "crime-db",
        "type": "database",
        "label": "Crime Database",
        "status": "failed",
        "position": { "x": 350, "y": 220 },
        "inspectable": true,
        "inspectData": {
          "title": "Banco de Dados Criminal",
          "logs": [
            "[00:00:02] WARN: Connection pool at 100% (500/500)",
            "[00:00:03] ERROR: Connection pool exhausted ‚Äî rejecting new connections",
            "[00:00:05] ERROR: 47,000 queries queued, avg response time > 30s",
            "[00:00:10] FATAL: Query timeout cascade ‚Äî system unresponsive"
          ],
          "data": {
            "Status": "OVERWHELMED",
            "Connection Pool": "500/500 (exhausted)",
            "Queued Queries": "47,000+",
            "Normal Query Rate": "~400/sec",
            "Current Query Rate": "~47,000/sec",
            "CPU": "100%"
          },
          "status": "Banco de dados esmagado pela avalanche de consultas de cache miss."
        }
      },
      {
        "id": "api-services",
        "type": "server",
        "label": "API Services",
        "status": "degraded",
        "position": { "x": 100, "y": 380 },
        "inspectable": true,
        "inspectData": {
          "title": "Frota de Servi√ßos de API",
          "logs": [
            "[00:00:03] ERROR: Cache MISS ‚Äî falling through to database",
            "[00:00:04] ERROR: Database connection timeout",
            "[00:00:05] ERROR: 503 Service Unavailable returned to clients"
          ],
          "data": {
            "Status": "FAILING",
            "Cache Miss Rate": "99.9%",
            "Error Rate": "87%"
          },
          "status": "Todas as requisi√ß√µes passam direto pelo cache e sobrecarregam o banco de dados."
        }
      },
      {
        "id": "dispatch",
        "type": "client",
        "label": "Dispatch Center",
        "status": "failed",
        "position": { "x": 550, "y": 380 },
        "inspectable": true,
        "inspectData": {
          "title": "Central de Despacho",
          "logs": [
            "[00:00:10] ERROR: Unable to retrieve case data",
            "[00:00:15] ERROR: Dispatch system unresponsive"
          ],
          "data": {
            "Status": "OFFLINE",
            "Pending Dispatches": "34",
            "Occurrence": "3rd consecutive Saturday"
          },
          "status": "Despacho fora do ar devido √† cascata de falhas upstream."
        }
      }
    ],
    "edges": [
      { "id": "e-api-cache", "source": "api-services", "target": "redis-cache", "label": "cache miss", "animated": true, "style": "broken" },
      { "id": "e-api-db", "source": "api-services", "target": "crime-db", "label": "fallback queries", "animated": true, "style": "slow" },
      { "id": "e-cache-db", "source": "redis-cache", "target": "crime-db", "label": "cache rebuild", "animated": true, "style": "slow" },
      { "id": "e-dispatch-api", "source": "dispatch", "target": "api-services", "label": "requests", "animated": false, "style": "broken" }
    ]
  },
  "diagnosis": {
    "rootCause": {
      "question": "Qual √© a causa raiz do banco de dados ficar sobrecarregado todo s√°bado √† meia-noite?",
      "options": [
        {
          "id": "rc-1",
          "text": "O banco de dados est√° subdimensionado e precisa de mais capacidade no pool de conex√µes",
          "correct": false,
          "feedback": "O banco de dados lida com a carga normal bem a ~400 consultas/seg. O problema √© o pico repentino para 47.000 consultas/seg causado por todas as entradas de cache expirando simultaneamente. Um pool de conex√µes maior apenas atrasaria o inevit√°vel."
        },
        {
          "id": "rc-2",
          "text": "Todas as entradas de cache foram configuradas com o mesmo TTL, causando expira√ß√£o simult√¢nea e criando uma avalanche de consultas ao banco de dados",
          "correct": true,
          "feedback": "Correto! Isto √© uma avalanche de cache (tamb√©m chamada de cache stampede). Quando todas as chaves compartilham o mesmo TTL e foram configuradas ao mesmo tempo, todas expiram juntas. A inunda√ß√£o repentina de cache misses sobrecarrega o banco de dados. A solu√ß√£o √© adicionar jitter aleat√≥rio aos valores de TTL para que as expira√ß√µes sejam distribu√≠das ao longo do tempo."
        },
        {
          "id": "rc-3",
          "text": "O Redis est√° caindo √† meia-noite devido a um problema de mem√≥ria",
          "correct": false,
          "feedback": "O Redis n√£o est√° caindo ‚Äî est√° funcionando exatamente como projetado. As chaves est√£o expirando no prazo porque todas t√™m o mesmo TTL. O problema √© o padr√£o de expira√ß√£o, n√£o a estabilidade do Redis."
        },
        {
          "id": "rc-4",
          "text": "O job de aquecimento de cache de s√°bado √† meia-noite est√° conflitando com opera√ß√µes normais",
          "correct": false,
          "feedback": "O job de aquecimento de cache √© na verdade a causa do problema de TTL uniforme ‚Äî ele carrega todas as chaves ao mesmo tempo com o mesmo TTL. Mas a causa raiz √© o padr√£o de TTL id√™ntico, n√£o o job de aquecimento em si."
        }
      ]
    },
    "fix": {
      "question": "Qual √© a melhor solu√ß√£o para prevenir a avalanche de cache?",
      "options": [
        {
          "id": "fix-1",
          "text": "Adicionar jitter aleat√≥rio aos TTLs do cache para que as entradas expirem em momentos diferentes em vez de todas de uma vez",
          "correct": true,
          "feedback": "Correto! Ao adicionar um deslocamento aleat√≥rio ao TTL de cada chave (ex.: 7 dias + aleat√≥rio de 0-60 minutos), as expira√ß√µes s√£o distribu√≠das ao longo do tempo em vez de acontecerem simultaneamente. Isso previne a debandada e mant√©m a carga do banco de dados suave. Esta √© a defesa padr√£o contra avalanche de cache."
        },
        {
          "id": "fix-2",
          "text": "Dobrar o tamanho do pool de conex√µes do banco de dados para suportar o pico",
          "correct": false,
          "feedback": "Mesmo dobrando o pool (para 1.000) n√£o √© poss√≠vel lidar com 47.000+ consultas simult√¢neas. Seria necess√°rio um aumento de 100x, o que desperdi√ßa recursos 99,9% do tempo. √â melhor prevenir o pico em primeiro lugar com TTLs escalonados."
        },
        {
          "id": "fix-3",
          "text": "Nunca deixar as entradas de cache expirarem ‚Äî mant√™-las para sempre e atualizar manualmente",
          "correct": false,
          "feedback": "Entradas de cache que nunca expiram levam a dados desatualizados e crescimento ilimitado de mem√≥ria. Expira√ß√£o √© um mecanismo saud√°vel de cache ‚Äî o problema √© expira√ß√£o sincronizada, n√£o expira√ß√£o em si."
        },
        {
          "id": "fix-4",
          "text": "Executar o job de aquecimento de cache com mais frequ√™ncia (diariamente em vez de semanalmente)",
          "correct": false,
          "feedback": "Executar o job de aquecimento diariamente com o mesmo TTL uniforme apenas muda a avalanche para acontecer toda noite em vez de semanalmente. O problema central ‚Äî TTLs id√™nticos causando expira√ß√£o sincronizada ‚Äî permanece inalterado."
        }
      ]
    }
  },
  "conceptId": "cache-expiry-strategies",
  "badge": {
    "name": "Guarda da Avalanche",
    "icon": "üèîÔ∏è"
  }
}
